# ОФФТОП реалтизация спин-лока и что зачем появилось и их развитие

## Спинлок — это просто переменная, которая содержит ноль или единицу (бывают варианты).

Если ноль — спинлок свободен, и его можно захватить. 
Если не ноль — спинлок заперт, и нить, которая желает его захватить, 
будет ждать, крутясь (spin — вращение) в небольшом цикле непрерывной проверки освобождения спинлока. 
Вот, собственно, реализация:

```cpp
    while( !  _spin_try_lock( &(sl->lock)  ) )
        while( sl->lock )
            ;
```

Операция **_spin_try_lock** — атомарная, реализована на ассемблере соответствующего процессора. 
Пытаемся запереть спинлок, если не удалось — крутимся в цикле, пока он заперт, потом снова пытаемся.

Первая инструкция — **load linked** — просто читает значение из памяти. 
Но при этом в процессоре взводится триггер, который «следит» за считанной ячейкой — не было ли в неё записи.

Вторая — **store conditional** — сохраняет значение в память. 
Но! Если со времени исполнения load linked в эту ячейку кто-то уже записал новое значение, 
store conditional вернёт признак неуспеха (и, конечно, ничего в ячейку памяти записывать не будет).

# Compare-And-Swap (CAS) — это атомарная инструкция для многопоточной обработки, 
которая сравнивает значение в памяти с ожидаемым значением и, 
если они совпадают, атомарно заменяет его новым значением, 
возвращая результат операции (успешно или нет).

## Test-and-set (или TSL) — это атомарная инструкция или операция, 
которая позволяет одновременно прочитать значение переменной и установить новое значение, 
при этом гарантируя, что никакие другие операции не будут выполнены между чтением и установкой значения.

**Атомики**

В конкурентном программировании атомики — это тип объектов, 
позволяющие множеству потоков получать доступ к переменной и модифицировать её потокобезопасным образом. 
Они обеспечивают необходимую синхронизацию и барьеры памяти 

**Барьеры памяти**

Барьер памяти — это своеобразный аппаратный или программный механизм синхронизации, 
гарантирующий, что все обращения к памяти на конкретном процессоре выполняются в определённом порядке. 
С их помощью обеспечивается согласованность последовательных операций – эта модель, 
применяемая в конкурентном программировании, обеспечивает одинаковый порядок операций для всех потоков.

- 1. **Барьеры компилятора**: это инструкции, вставляемые компилятором во избежание переупорядочивания кода. 
 Они гарантируют, что код будет выполняться именно в том порядке, 
 в котором записан — так можно избежать некорректного поведения. 
 Как правило, такие барьеры используются для оптимизации кода и повышения производительности, 
 но в некоторых случаях могут применяться и для устранения проблем с конкурентностью.

- 2. **Барьеры процессора**: Барьеры процессора — это процессорные инструкции, гарантирующие, 
  что операции над памятью выполняются в конкретном порядке. 
  Они не позволяют процессору нарушать ход инструкций, и пренебрежение этим правилом в конкурентной программе 
  приведёт к некорректному поведению. 
  Как правило, процессорные барьеры реализуются при помощи специальных инструкций или протоколов когерентности кэша.

- 3. **Барьер сохранения**: Барьер сохранения (также называемый барьер записи) — это барьер памяти, 
  гарантирующий, что все операции сохранения в память до достижения барьера будут видимы другим потокам. 
  Барьеры сохранения не позволяют процессору переупорядочивать операции сохранения в память. 
  В противном случае операция записи в одном потоке могла бы сработать до операции чтения в другом потоке.

- 4. **Барьер загрузки**: барьер загрузки (также называемый барьер чтения) — это барьер памяти, гарантирующий, 
  что все операции загрузки в память после барьера будут видны актуальному потоку. 
  Барьеры загрузки не позволяют процессору переупорядочивать операции загрузки в память. 
  В противном случае операция чтения могла бы быть выполнена до операции записи в другом потоке.

- 5. **Полный барьер**: полный барьер (также именуемый тотальным) — это барьер памяти, гарантирующий, 
  что все операции в памяти до барьера видимы всем потокам, а все операции после барьера видимы только текущему потоку. 
  Полные барьеры обеспечивают наивысший уровень синхронизации и самые сильные гарантии упорядочивания. 
  Обычно они используются, когда требуется максимальная синхронизация.

```cpp
class SpinLock {
  public:
    SpinLock() {}

    void lock() {
        retries = 0;
        while (flag.test_and_set(std::memory_order_acquire)) {
            // spin until the lock is released
            backoff();
            retries++;
        }
    }

    void unlock() {
        flag.clear(std::memory_order_release);
    }

  private:
    void backoff() {
        const int max_retries = 8;
        if (retries < max_retries) {
            std::this_thread::yield();
        } else {
            auto delay = std::chrono::microseconds(1 << (retries - max_retries));
            std::this_thread::sleep_for(delay);
        }
    }

    std::atomic_flag flag = ATOMIC_FLAG_INIT;
    int retries{0};
};
``` 
Чтобы приобрести блокировку, мы применяем метод **test_and_set()** к std::memory_order_acquire. Так создаётся барьер памяти, гарантирующий, что все предыдущие операции записи будут видны потоку до тех пор, пока он не приобретёт блокировку. Затем мы применяем метод clear() к std::memory_order_release, чтобы высвободить блокировку, и тем самым выставляем барьер памяти, гарантирующий, что после снятия блокировки все последующие операции записи будут видны другим потокам.

В методе backoff(), который у нас вызывается внутри метода lock() в теле нашего цикла while, мы продолжаем крутиться, пока не достигнем жёстко запрограммированного количества попыток. Далее, израсходовав нашу квоту процессорного времени, мы просто уступаем процессор методом std::this_thread::yield(). После достижения показателя max_retries, мы будем постепенно выжидать всё большие отрезки времени (в микросекундах), а затем выполнять следующую попытку. Учтите: я исхожу из того, что вы не работаете с операционной системой реального времени, поэтому здесь мы работаем с аппроксимацией времени.

# Futex

Общая идея **futex (Fast Userspace Mutex)** — создать низкоуровневый, легкий механизм синхронизации в операционной системе Linux, который минимизирует обращения к ядру при конкурентном доступе к ресурсам, обеспечивая высокую производительность и масштабируемость в многопоточных приложениях. Futex работает, позволяя процессам ждать в пользовательском пространстве, а при необходимости — переводить их в состояние ожидания в ядре с помощью системных вызовов **futex_wait** и **futex_wake**, которые осуществляют управление списками потоков, ожидающих на определенных адресах. 

- из мануала 
-      The futex() system call provides a method for waiting until a
       certain condition becomes true.  It is typically used as a
       blocking construct in the context of shared-memory
       synchronization.  When using futexes, the majority of the
       synchronization operations are performed in user space.  A user-
       space program employs the futex() system call only when it is
       likely that the program has to block for a longer time until the
       condition becomes true.  Other futex() operations can be used to
       wake any processes or threads waiting for a particular condition.